import logging
import re
import asyncio
import aiohttp
import time
import urllib.parse
from collections import deque
from telegram import Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler
import random

# ----------------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª -----------------
BOT_TOKEN = '8363277121:AAH4wGsId1uUUucQavaG8uvb31mknRkDT5Q'
TARGET_CHAT_ID = '@proxy_iran2024'
GITHUB_SOURCE = 'https://raw.githubusercontent.com/Argh94/telegram-proxy-scraper/main/proxy.txt'

CHECK_INTERVAL = 120  # Ø§Ø¬Ø±Ø§ Ù‡Ø± 2 Ø¯Ù‚ÛŒÙ‚Ù‡
PING_TIMEOUT = 1.5    # ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø³Ø®Øªâ€ŒÚ¯ÛŒØ±Ø§Ù†Ù‡ (Ø«Ø§Ù†ÛŒÙ‡)
PING_RETRIES = 3      # ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙØ¹Ø§Øª ØªØ³Øª Ù‡Ø± Ù¾Ø±ÙˆÚ©Ø³ÛŒ
REQUIRED_COUNT = 16   # ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„

# Ø¬Ù…Ù„Ø§Øª Ø§Ù†Ú¯ÛŒØ²Ø´ÛŒ
PERSIAN_QUOTES = [
    "Ù…ÙˆÙÙ‚ÛŒØª Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ§ÛŒ Ø§Ø² ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø§Ø³Øª Ú©Ù‡ Ù‡Ø± Ø±ÙˆØ² ØªÚ©Ø±Ø§Ø± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.",
    "Ø³Ø®ØªÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù†ÛŒØ³ØªÙ†Ø¯ Ú©Ù‡ ØªÙˆ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†Ù†Ø¯ØŒ Ø¨Ù„Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ù†Ø¯ Ú©Ù‡ ØªÙˆ Ø±Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ú©Ù†Ù†Ø¯.",
    "Ø¢ÛŒÙ†Ø¯Ù‡â€ŒØ§Øª Ø±Ø§ Ø¨Ø§ Ú©Ø§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ù…Ø±ÙˆØ² Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒ Ø¨Ø³Ø§Ø²ØŒ Ù†Ù‡ Ø¨Ø§ Ú©Ø§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ ÙØ±Ø¯Ø§ Ù‚ØµØ¯ Ø¯Ø§Ø±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒ.",
    "Ø±ÙˆÛŒØ§Ù‡Ø§ ØªØ§Ø±ÛŒØ® Ø§Ù†Ù‚Ø¶Ø§ Ù†Ø¯Ø§Ø±Ù†Ø¯ØŒ Ù†ÙØ³ÛŒ ØªØ§Ø²Ù‡ Ø¨Ú©Ø´ Ùˆ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†.",
    "Ø´Ø¬Ø§Ø¹Øª ÛŒØ¹Ù†ÛŒ ØªØ±Ø³ÛŒØ¯Ù† Ùˆ Ù„Ø±Ø²ÛŒØ¯Ù†ØŒ Ø§Ù…Ø§ Ø¨Ø±Ø¯Ø§Ø´ØªÙ† Ù‚Ø¯Ù… Ø§ÙˆÙ„.",
]

# ----------------- Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ -----------------
HISTORY_SET = set()
UNTESTED_QUEUE = deque()

# ----------------- Ù„Ø§Ú¯ -----------------
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ----------------- ØªÙˆØ§Ø¨Ø¹ -----------------
def parse_proxy_info(proxy_url):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ IP Ùˆ Ù¾ÙˆØ±Øª Ø§Ø² Ù„ÛŒÙ†Ú© Ù¾Ø±ÙˆÚ©Ø³ÛŒ"""
    try:
        url_for_parse = proxy_url.replace('tg://', 'http://').replace('t.me', 'http://')
        parsed = urllib.parse.urlparse(url_for_parse)
        qs = urllib.parse.parse_qs(parsed.query)
        server = qs.get('server', [None])[0]
        port = qs.get('port', [None])[0]
        if server and port:
            return server, int(port)
    except Exception:
        pass
    return None, None

async def measure_latency_average(ip, port, retries=3):
    """Ù¾ÛŒÙ†Ú¯ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø¬Ø´ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ"""
    latencies = []
    for _ in range(retries):
        start_time = time.time()
        try:
            future = asyncio.open_connection(ip, port)
            reader, writer = await asyncio.wait_for(future, timeout=PING_TIMEOUT)
            latency = (time.time() - start_time) * 1000
            latencies.append(latency)
            writer.close()
            await writer.wait_closed()
            await asyncio.sleep(0.1)
        except (asyncio.TimeoutError, ConnectionRefusedError, OSError):
            return False, 9999
        except Exception:
            return False, 9999
    avg_latency = sum(latencies) / len(latencies) if latencies else 9999
    return True, int(avg_latency)

async def fetch_source_proxies():
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨"""
    global UNTESTED_QUEUE, HISTORY_SET
    try:
        timeout = aiohttp.ClientTimeout(total=20)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(GITHUB_SOURCE) as response:
                if response.status == 200:
                    text = await response.text()
                    matches = re.findall(r'(tg://proxy\?[\w=&.-]+|https://t\.me/proxy\?[\w=&.-]+)', text)
                    new_added = 0
                    for link in matches:
                        clean_link = link.replace('tg://', 'https://t.me/')
                        if clean_link not in HISTORY_SET and clean_link not in UNTESTED_QUEUE:
                            UNTESTED_QUEUE.append(clean_link)
                            new_added += 1
                    if new_added > 0:
                        logger.info(f"ğŸ“¥ {new_added} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯. ØµÙ ÙØ¹Ù„ÛŒ: {len(UNTESTED_QUEUE)}")
                else:
                    logger.warning(f"âš ï¸ Ø®Ø·Ø§ÛŒ Ø³Ø±ÙˆØ± Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨: {response.status}")
    except aiohttp.ClientError as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡: {e}")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡: {e}")

async def send_formatted_message(bot, cats):
    """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡"""
    quote = random.choice(PERSIAN_QUOTES)
    msg = f"<i>{quote}</i>\n\n{'â€”'*20}\n<b>ğŸš€ Ù„ÛŒØ³Øª Ø¬Ø¯ÛŒØ¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø± Ùˆ Ù¾Ø±Ø³Ø±Ø¹Øª</b>\nğŸ“¡ ØªÙÚ©ÛŒÚ© Ø´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø´Ø¨Ú©Ù‡\n\n"
    
    def build_section(title, proxies, emoji):
        section = f"{emoji} <b>{title}</b>\n"
        for i, item in enumerate(proxies, 1):
            section += f"ğŸ”— <a href='{item['url']}'>Ø§ØªØµØ§Ù„ {i}</a>  "
            if i % 2 == 0: section += "\n"
        return section + "\n"

    msg += build_section("Ù…Ø®ØµÙˆØµ Ù‡Ù…Ø±Ø§Ù‡ Ø§ÙˆÙ„ (MCI)", cats['mci'], "ğŸ”µ")
    msg += build_section("Ù…Ø®ØµÙˆØµ Ø§ÛŒØ±Ø§Ù†Ø³Ù„ (Irancell)", cats['irancell'], "ğŸŸ¡")
    msg += build_section("Ù…Ø®ØµÙˆØµ Ø±Ø§ÛŒØªÙ„ (Rightel)", cats['rightel'], "ğŸŸ£")
    msg += build_section("Ù…Ø®ØµÙˆØµ ÙˆØ§ÛŒâ€ŒÙØ§ÛŒ (WiFi/ADSL)", cats['wifi'], "âšªï¸")
    msg += "â€”"*20 + f"\nğŸ†” <b><a href='https://t.me/proxy_iran2024'>@proxy_iran2024</a></b>"

    try:
        await bot.send_message(
            chat_id=TARGET_CHAT_ID,
            text=msg,
            parse_mode=ParseMode.HTML,
            disable_web_page_preview=True
        )
        logger.info("ğŸ“¤ Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…: {e}")

async def process_proxies_job(context: ContextTypes.DEFAULT_TYPE):
    """Job Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§"""
    global UNTESTED_QUEUE, HISTORY_SET
    bot = context.bot
    logger.info("ğŸ”„ Ø´Ø±ÙˆØ¹ Ø³ÛŒÚ©Ù„ ØªØ³Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§...")

    if len(UNTESTED_QUEUE) < 50:
        await fetch_source_proxies()

    healthy_proxies = []
    attempts = 0
    max_attempts = 100

    while len(healthy_proxies) < REQUIRED_COUNT and UNTESTED_QUEUE and attempts < max_attempts:
        attempts += 1
        proxy_url = UNTESTED_QUEUE.popleft()
        HISTORY_SET.add(proxy_url)
        ip, port = parse_proxy_info(proxy_url)
        if ip and port:
            is_stable, avg_ping = await measure_latency_average(ip, port, retries=PING_RETRIES)
            if is_stable:
                healthy_proxies.append({'url': proxy_url, 'ping': avg_ping})
                logger.info(f"âœ… Ù¾Ø±ÙˆÚ©Ø³ÛŒ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯ (Ping Avg: {avg_ping}ms) - {len(healthy_proxies)}/{REQUIRED_COUNT}")

    if len(healthy_proxies) >= REQUIRED_COUNT:
        healthy_proxies.sort(key=lambda x: x['ping'])
        top_16 = healthy_proxies[:REQUIRED_COUNT]
        categories = {
            "mci": top_16[0:4],
            "irancell": top_16[4:8],
            "rightel": top_16[8:12],
            "wifi": top_16[12:16]
        }
        await send_formatted_message(bot, categories)
    else:
        logger.warning(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§ÙÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {len(healthy_proxies)}")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("âœ… Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ Ø´Ø¯!\nÙ…ØªØ¯ ØªØ³Øª: Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒÙ†Ú¯ (3x) Ø¨Ø±Ø§ÛŒ ØªØ¶Ù…ÛŒÙ† Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ.")

# ----------------- Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª -----------------
async def main():
    print("--- Ø±Ø¨Ø§Øª Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Multi-Ping Stability Check) ---")
    application = ApplicationBuilder().token(BOT_TOKEN).build()
    application.add_handler(CommandHandler('start', start))

    # Job Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù‡Ø± 2 Ø¯Ù‚ÛŒÙ‚Ù‡
    application.job_queue.run_repeating(process_proxies_job, interval=CHECK_INTERVAL, first=5)

    # Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª
    await application.run_polling()

if __name__ == "__main__":
    asyncio.run(main())
